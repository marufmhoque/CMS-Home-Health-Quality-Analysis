# Analysis of CMS Home Health Agency Quality Metrics
## CRISP-DM Phase 1: Business Understanding, the goal was to define questions that would be answered based on the dataset.
In this project, I analyze CMS Home Health Quality data to answer three key business questions:
1. **Ownership Impact:** Do Non-Profit agencies achieve higher Star Ratings than For-Profit agencies?
2. **Geographic Performance:** Which states lead the country in patient mobility improvement?
3. **Predictive Modeling:** Can clinical performance metrics (Timely Care and Mobility Improvement) predict if an agency earns a "High" (4-5 star) rating?

## CRISP-DM Phase 2: Data Understanding, the primary features such as column headings were extracted to read the data.
In this section, I load the raw data and perform a basic inspection of the structure and column names to identify the features required for analysis.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load the first CSV file found in the directory
files = [f for f in os.listdir() if f.endswith('.csv')]
if not files:
    print("No CSV file found. Please upload the CMS dataset.")
else:
    df_raw = pd.read_csv(files[0], encoding='latin1')
    print(f"Successfully loaded {files[0]}")
    print(f"Dataset Dimensions: {df_raw.shape}")
    display(df_raw.head())

## CRISP-DM Phase 3: Data Preparation, here the data was cleaned and prepared for use
I have created a modular function `clean_cms_data` to process the raw data. This function handles column identification, renaming, numeric conversion (removing '%' and handling '-' placeholders), and missing value imputation.

def clean_cms_data(df):
    '''
    INPUT: 
    df - the raw CMS dataframe
    
    OUTPUT:
    df_prepared - a cleaned dataframe with renamed columns and numeric types
    '''
    # 1. Identify columns using keywords to make code robust
    star_col = [c for c in df.columns if 'star rating' in c.lower() and 'care' in c.lower()][0]
    timely_col = [c for c in df.columns if 'timely' in c.lower()][0]
    walking_col = [c for c in df.columns if 'walking' in c.lower() or 'ambulation' in c.lower()][0]

    # 2. Filter and Rename
    cols = ['State', 'Type of Ownership', star_col, timely_col, walking_col]
    df_prepared = df[cols].copy()
    df_prepared.columns = ['State', 'Ownership', 'Star_Rating', 'Timely_Care', 'Mobility_Improvement']

    # 3. Numeric Cleaning: Handle %, -, and 'Not Available'
    for col in ['Star_Rating', 'Timely_Care', 'Mobility_Improvement']:
        df_prepared[col] = df_prepared[col].astype(str).str.replace('%', '').str.strip()
        df_prepared[col] = pd.to_numeric(df_prepared[col], errors='coerce')

    # 4. Handle Missing Values
    # Drop rows where the target (Star_Rating) is null
    df_prepared = df_prepared.dropna(subset=['Star_Rating'])
    
    # Impute missing clinical values with the mean
    df_prepared['Timely_Care'] = df_prepared['Timely_Care'].fillna(df_prepared['Timely_Care'].mean())
    df_prepared['Mobility_Improvement'] = df_prepared['Mobility_Improvement'].fillna(df_prepared['Mobility_Improvement'].mean())
    
    return df_prepared

# Execute Preparation Module
df_prepared = clean_cms_data(df_raw)
print("Data Preparation Module Complete.")

## CRISP-DM Phase 4: Modeling & Visualization, this section had a goal to answer the first two questions
I visualize the data to answer my first two business questions regarding Ownership and Geography.

def plot_ownership_impact(df):
    '''Visualizes average star rating by ownership type.'''
    plt.figure(figsize=(10,5))
    # Filter out unknown/dash ownership labels
    df_plot = df[df['Ownership'] != '-']
    df_plot.groupby('Ownership')['Star_Rating'].mean().sort_values().plot(kind='barh', color='skyblue')
    plt.title('Average Star Rating by Ownership Type')
    plt.xlabel('Average Star Rating')
    plt.savefig('ownership_impact.png', bbox_inches='tight')
    plt.show()

def plot_geographic_performance(df):
    '''Visualizes top 10 states for mobility improvement.'''
    plt.figure(figsize=(12,5))
    df.groupby('State')['Mobility_Improvement'].mean().sort_values(ascending=False).head(10).plot(kind='bar', color='salmon')
    plt.title('Top 10 States for Patient Mobility Improvement')
    plt.ylabel('Avg % Patients Improved')
    plt.ylim(0, 100)
    plt.savefig('geographic_performance.png', bbox_inches='tight')
    plt.show()

# Run Descriptive Visuals
plot_ownership_impact(df_prepared)
plot_geographic_performance(df_prepared)

## CRISP-DM Phase 5: Evaluation
I modularized the machine learning workflow into a training and evaluation function. I use a Random Forest Classifier to predict high-rated agencies and evaluate the model using an accuracy score and feature importance.

def train_and_evaluate_rf(df):
    '''
    INPUT: Prepared DataFrame
    OUTPUT: Trained model and feature set
    '''
    # Create target: 1 if Star_Rating >= 4, else 0
    df['is_high_rated'] = (df['Star_Rating'] >= 4).astype(int)
    
    # Select Features and Target
    X = df[['Timely_Care', 'Mobility_Improvement']]
    y = df['is_high_rated']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train Random Forest
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    
    # Predict and Score
    preds = model.predict(X_test)
    print(f"Model Accuracy: {accuracy_score(y_test, preds):.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, preds))
    
    return model, X

def plot_feature_importance(model, X):
    '''Plots the importance of features in the predictive model.'''
    importances = model.feature_importances_
    feat_importances = pd.Series(importances, index=X.columns)
    plt.figure(figsize=(8,4))
    feat_importances.sort_values().plot(kind='barh', color='teal')
    plt.title('Feature Importance for High Star Ratings')
    plt.savefig('feature_importance.png', bbox_inches='tight')
    plt.show()

# Run Predictive Modules
rf_model, X_cols = train_and_evaluate_rf(df_prepared)
plot_feature_importance(rf_model, X_cols)

## CRISP-DM Phase 6: Deployment
The findings of this project are deployed via a blog post on Medium. 
### Key Insights Summary:
1. **Ownership:** Non-profit agencies outperform proprietary (for-profit) agencies in quality star ratings.
2. **Geography:** Rhode Island and Kentucky are national leaders in patient mobility outcomes.
3. **Predictors:** Patient Mobility Improvement is a slightly more significant indicator of an agency's star rating than the timeliness of care initiation.
